{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "# regressor.py \n",
    "This Python notebook uses a few different methods to built regressors for the data provided by Dr. Chawla's challenge assignment.  Based on how the regression functions perform according to various validation frameworks, it chooses the best regression function to predict for the data included as testing data.  It writes this in a one column format to a file called \"regression_test.predictions\"\n",
    "### Margaret Thomann & Michael McRoskey\t\n",
    "#### May 7 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training, testing and prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"../data/regression_train.data\"\n",
    "TEST_FILE = \"../data/regression_test.test\"\n",
    "PREDICTION_FILE = \"../data/regression_test.predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading training and testing data into data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading training data into pandas data frame\n",
    "features_train = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \n",
    "\t\t\t\"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \n",
    "\t\t\t\"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \n",
    "\t\t\t\"f19\", \"f20\", \"f21\", \n",
    "\t\t\t\"Value\"]\n",
    "df_train = pd.read_csv(TRAIN_FILE, names=features_train)\n",
    "\n",
    "# Read testing data into pandas data frame\n",
    "features_test = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \n",
    "\t\t\t\"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \n",
    "\t\t\t\"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \n",
    "\t\t\t\"f19\", \"f20\", \"f21\"]\n",
    "df_test = pd.read_csv(TEST_FILE, names=features_test)\n",
    "\n",
    "# Define x and y from data\n",
    "#     x_* arrays will be transformed later in \"Feature Selection\"\n",
    "x = df_train.drop(['Value'], axis=1)\n",
    "x_a = df_train.drop(['Value'], axis=1)\n",
    "x_b = df_train.drop(['Value'], axis=1)\n",
    "x_c = df_train.drop(['Value'], axis=1)\n",
    "y = df_train['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "* **a** : x_a is the non-transformed data; no feature selection has been performed \n",
    "* **b** : x_b is the transformed data using the ExtraTreesClassifier \n",
    "* **c** : x_c is the transformed data using the VarianceThreshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_a shape: (5460, 21)\n",
      "x_b shape: (5460, 12)\n",
      "x_c shape: (5460, 19)\n"
     ]
    }
   ],
   "source": [
    "# Tree Based Feature Selection\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(x, y)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "x_b = model.transform(x)\n",
    "\n",
    "# Low Variance Removal\n",
    "# sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "# x_c = sel.fit_transform(x_c)\n",
    "x_c = SelectKBest(chi2, k=19).fit_transform(x, y)\n",
    "\n",
    "\n",
    "print \"x_a shape:\", x_a.shape\n",
    "print \"x_b shape:\", x_b.shape\n",
    "print \"x_c shape:\", x_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building & validating regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Building Regression---\n",
      "\t * Linear Regression Model built for iteration:  0\n",
      "\t * Random Forest Regression built for iteration:  0\n",
      "\t * Gradient Boosting Regression built for iteration:  0\n",
      "\n",
      "\n",
      "\t * Linear Regression Model built for iteration:  1\n",
      "\t * Random Forest Regression built for iteration:  1\n",
      "\t * Gradient Boosting Regression built for iteration:  1\n",
      "\n",
      "\n",
      "\t * Linear Regression Model built for iteration:  2\n",
      "\t * Random Forest Regression built for iteration:  2\n",
      "\t * Gradient Boosting Regression built for iteration:  2\n",
      "\n",
      "\n",
      "---COMPLETE:  Building Regression---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print \"---Building Regression---\" \n",
    "# Define the number of regression functions for performance metrics later\n",
    "NUM_REGRESSORS = 3\n",
    "\n",
    "# Loop through to build classifiers for each transformed x array\n",
    "x_array = [x_a, x_b, x_c]\n",
    "results = []\n",
    "results_accuracy = []\n",
    "for i in range(len(x_array)):\n",
    "    \n",
    "    '''Linear Regression'''\n",
    "    lin_reg = linear_model.LinearRegression()\n",
    "    lin_reg.fit(x_array[i], y)\n",
    "    cv_results_lin_reg = cross_val_score(lin_reg, x_array[i], y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    cv_results_lin_reg_accuracy = cross_val_score(lin_reg, x_array[i], y, cv=10)\n",
    "    results.append(cv_results_lin_reg)\n",
    "    results_accuracy.append(cv_results_lin_reg_accuracy)\n",
    "    print \"\\t * Linear Regression Model built for iteration: \", i\n",
    "\n",
    "    '''Random Forest Regression'''\n",
    "    rf_reg = RandomForestRegressor()\n",
    "    rf_reg.fit(x_array[i], y)\n",
    "    cv_results_rf_reg = cross_val_score(rf_reg, x_array[i], y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    cv_results_rf_reg_accuracy = cross_val_score(rf_reg, x_array[i], y, cv=10)\n",
    "    results.append(cv_results_rf_reg)\n",
    "    results_accuracy.append(cv_results_rf_reg_accuracy)\n",
    "    print \"\\t * Random Forest Regression built for iteration: \", i \n",
    "    \n",
    "    '''Gradient Boosting Regression'''\n",
    "    gb_reg = GradientBoostingRegressor()\n",
    "    gb_reg.fit(x_array[i], y)\n",
    "    cv_results_gb_reg = cross_val_score(gb_reg, x_array[i], y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    cv_results_gb_reg_accuracy = cross_val_score(gb_reg, x_array[i], y, cv=10)\n",
    "    results.append(cv_results_gb_reg)\n",
    "    results_accuracy.append(cv_results_gb_reg_accuracy)\n",
    "    print \"\\t * Gradient Boosting Regression built for iteration: \", i \n",
    "    print \"\\n\"\n",
    "\n",
    "print \"---COMPLETE:  Building Regression---\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Performance Metrics with Neg_Mean_Squared_Error---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                                   </td><td>Linear Regression </td><td>Random Forest Regression</td><td>Gradient Boosting Regression</td></tr>\n",
       "<tr><td>a. No Feature Selection            </td><td>-91.17 (+/- 48.96)</td><td>-6.82 (+/- 1.47)        </td><td>-5.99 (+/- 2.57)            </td></tr>\n",
       "<tr><td>b. Extra Trees Feature Selection   </td><td>-95.08 (+/- 51.27)</td><td>-7.02 (+/- 1.11)        </td><td>-6.68 (+/- 2.69)            </td></tr>\n",
       "<tr><td>c. Select 19 Best Feature Selection</td><td>-91.54 (+/- 48.09)</td><td>-6.85 (+/- 2.36)        </td><td>-6.13 (+/- 2.88)            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Performance Metrics with Accuracy---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>                                   </td><td>Linear Regression</td><td>Random Forest Regression</td><td>Gradient Boosting Regression</td></tr>\n",
       "<tr><td>a. No Feature Selection            </td><td>0.72 (+/- 0.12)  </td><td>0.98 (+/- 0.01)         </td><td>0.98 (+/- 0.01)             </td></tr>\n",
       "<tr><td>b. Extra Trees Feature Selection   </td><td>0.71 (+/- 0.12)  </td><td>0.98 (+/- 0.01)         </td><td>0.98 (+/- 0.01)             </td></tr>\n",
       "<tr><td>c. Select 19 Best Feature Selection</td><td>0.72 (+/- 0.11)  </td><td>0.98 (+/- 0.01)         </td><td>0.98 (+/- 0.01)             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"---Performance Metrics with Neg_Mean_Squared_Error---\")\n",
    "table = []\n",
    "table.append([\"\", \"Linear Regression\", \"Random Forest Regression\", \"Gradient Boosting Regression\"])\n",
    "column_names = [\"a. No Feature Selection\", \"b. Extra Trees Feature Selection\", \"c. Select 19 Best Feature Selection\"]\n",
    "table_row = []\n",
    "col_counter = 0\n",
    "for i in range(len(x_array)*NUM_REGRESSORS):\n",
    "    mean = results[i].mean()\n",
    "    std = results[i].std()\n",
    "    str_results = \"%0.2f (+/- %0.2f)\" % (mean, std * 2)\n",
    "    table_row.append(str_results)\n",
    "    if ((i+1) % 3 == 0):\n",
    "        table_row.insert(0, column_names[col_counter])\n",
    "        table.append(table_row)\n",
    "        table_row = []\n",
    "        col_counter += 1\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "\n",
    "print(\"---Performance Metrics with Accuracy---\")\n",
    "table = []\n",
    "table.append([\"\", \"Linear Regression\", \"Random Forest Regression\", \"Gradient Boosting Regression\"])\n",
    "column_names = [\"a. No Feature Selection\", \"b. Extra Trees Feature Selection\", \"c. Select 19 Best Feature Selection\"]\n",
    "table_row = []\n",
    "col_counter = 0\n",
    "for i in range(len(x_array)*NUM_REGRESSORS):\n",
    "    mean = results_accuracy[i].mean()\n",
    "    std = results_accuracy[i].std()\n",
    "    str_results = \"%0.2f (+/- %0.2f)\" % (mean, std * 2)\n",
    "    table_row.append(str_results)\n",
    "    if ((i+1) % 3 == 0):\n",
    "        table_row.insert(0, column_names[col_counter])\n",
    "        table.append(table_row)\n",
    "        table_row = []\n",
    "        col_counter += 1\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using regression function on test data\n",
    "It is clear from the tables above that Gradient Boosting Regression with no feature selection performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['Value'], axis=1)\n",
    "y_train = df_train['Value']\n",
    "\n",
    "# Fit Model\n",
    "final_regressor = GradientBoostingRegressor()\n",
    "final_regressor.fit(x_train, y_train)\n",
    "\n",
    "# Predict model\n",
    "predictions = final_regressor.predict(df_test)\n",
    "with open(PREDICTION_FILE, \"w+\") as f:\n",
    "    for number in predictions:\n",
    "        f.write(str(number)+\"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
