{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "# classifier.py \n",
    "This Python notebook uses a few different methods to built classifiers for the data provided by Dr. Chawla's challenge assignment.  Based on how the classifiers perform according to various validation frameworks, it chooses the best classifier to predict classes for the data included as testing data.  It writes this in a one column format to a file called \"classification_test.prediction\"\n",
    "### Margaret Thomann & Michael McRoskey\t\n",
    "#### May 7 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training, testing and prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"../data/classification_train.data\"\n",
    "TEST_FILE = \"../data/classification_test.test\"\n",
    "PREDICTION_FILE = \"../data/classification_test.predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading training and testing data into data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading training data into pandas data frame\n",
    "features_train = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \n",
    "\t\t\t\"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \n",
    "\t\t\t\"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \n",
    "\t\t\t\"f19\", \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \n",
    "\t\t\t\"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "\t\t\t\"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \n",
    "\t\t\t\"f37\", \"f38\", \"f39\", \"f40\", \"f41\", \"f42\", \n",
    "\t\t\t\"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\", \n",
    "\t\t\t\"Class\"]\n",
    "df_train = pd.read_csv(TRAIN_FILE, names=features_train)\n",
    "\n",
    "# Read testing data into pandas data frame\n",
    "features_test = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \n",
    "\t\t\t\"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \n",
    "\t\t\t\"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \n",
    "\t\t\t\"f19\", \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \n",
    "\t\t\t\"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \n",
    "\t\t\t\"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \n",
    "\t\t\t\"f37\", \"f38\", \"f39\", \"f40\", \"f41\", \"f42\", \n",
    "\t\t\t\"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\"]\n",
    "df_test = pd.read_csv(TRAIN_FILE, names=features_test)\n",
    "\n",
    "# Define x and y from data\n",
    "x_train = df_train.drop(['Class'], axis=1)\n",
    "y_train = df_train['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.79281667\n",
      "Iteration 2, loss = 0.55691945\n",
      "Iteration 3, loss = 0.53670280\n",
      "Iteration 4, loss = 0.52419689\n",
      "Iteration 5, loss = 0.50830559\n",
      "Iteration 6, loss = 0.51286194\n",
      "Iteration 7, loss = 0.50283461\n",
      "Iteration 8, loss = 0.49467388\n",
      "Iteration 9, loss = 0.49668432\n",
      "Iteration 10, loss = 0.48756198\n",
      "Iteration 11, loss = 0.49127997\n",
      "Iteration 12, loss = 0.49010697\n",
      "Iteration 13, loss = 0.48889923\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.59586065\n",
      "Iteration 2, loss = 0.59996715\n",
      "Iteration 3, loss = 0.54876264\n",
      "Iteration 4, loss = 0.53066195\n",
      "Iteration 5, loss = 0.52589170\n",
      "Iteration 6, loss = 0.51861085\n",
      "Iteration 7, loss = 0.51014537\n",
      "Iteration 8, loss = 0.50767877\n",
      "Iteration 9, loss = 0.51324499\n",
      "Iteration 10, loss = 0.49283616\n",
      "Iteration 11, loss = 0.49579039\n",
      "Iteration 12, loss = 0.50175358\n",
      "Iteration 13, loss = 0.48801758\n",
      "Iteration 14, loss = 0.48562526\n",
      "Iteration 15, loss = 0.48216750\n",
      "Iteration 16, loss = 0.49103970\n",
      "Iteration 17, loss = 0.48893090\n",
      "Iteration 18, loss = 0.48113045\n",
      "Iteration 19, loss = 0.47851502\n",
      "Iteration 20, loss = 0.47767045\n",
      "Iteration 21, loss = 0.48458875\n",
      "Iteration 22, loss = 0.48020108\n",
      "Iteration 23, loss = 0.48279931\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.56058021\n",
      "Iteration 2, loss = 0.56621676\n",
      "Iteration 3, loss = 0.52995101\n",
      "Iteration 4, loss = 0.51658702\n",
      "Iteration 5, loss = 0.51183636\n",
      "Iteration 6, loss = 0.51823342\n",
      "Iteration 7, loss = 0.50995294\n",
      "Iteration 8, loss = 0.50747231\n",
      "Iteration 9, loss = 0.49980968\n",
      "Iteration 10, loss = 0.49162220\n",
      "Iteration 11, loss = 0.49281489\n",
      "Iteration 12, loss = 0.50084375\n",
      "Iteration 13, loss = 0.49056093\n",
      "Iteration 14, loss = 0.48809255\n",
      "Iteration 15, loss = 0.48655796\n",
      "Iteration 16, loss = 0.49201475\n",
      "Iteration 17, loss = 0.48171434\n",
      "Iteration 18, loss = 0.48568326\n",
      "Iteration 19, loss = 0.48047995\n",
      "Iteration 20, loss = 0.48217362\n",
      "Iteration 21, loss = 0.48323023\n",
      "Iteration 22, loss = 0.47931541\n",
      "Iteration 23, loss = 0.48396767\n",
      "Iteration 24, loss = 0.47455157\n",
      "Iteration 25, loss = 0.47527643\n",
      "Iteration 26, loss = 0.47252348\n",
      "Iteration 27, loss = 0.47004848\n",
      "Iteration 28, loss = 0.47295501\n",
      "Iteration 29, loss = 0.46639017\n",
      "Iteration 30, loss = 0.46901522\n",
      "Iteration 31, loss = 0.46750128\n",
      "Iteration 32, loss = 0.46863605\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.50418944\n",
      "Iteration 2, loss = 0.58888566\n",
      "Iteration 3, loss = 0.53976993\n",
      "Iteration 4, loss = 0.51393738\n",
      "Iteration 5, loss = 0.51173949\n",
      "Iteration 6, loss = 0.51021623\n",
      "Iteration 7, loss = 0.50578657\n",
      "Iteration 8, loss = 0.50790842\n",
      "Iteration 9, loss = 0.49806572\n",
      "Iteration 10, loss = 0.49530387\n",
      "Iteration 11, loss = 0.49758447\n",
      "Iteration 12, loss = 0.49014396\n",
      "Iteration 13, loss = 0.49432979\n",
      "Iteration 14, loss = 0.48570424\n",
      "Iteration 15, loss = 0.48866149\n",
      "Iteration 16, loss = 0.48862316\n",
      "Iteration 17, loss = 0.48408056\n",
      "Iteration 18, loss = 0.47870521\n",
      "Iteration 19, loss = 0.48409996\n",
      "Iteration 20, loss = 0.48032741\n",
      "Iteration 21, loss = 0.48821880\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.86183238\n",
      "Iteration 2, loss = 0.63150449\n",
      "Iteration 3, loss = 0.56561541\n",
      "Iteration 4, loss = 0.53896434\n",
      "Iteration 5, loss = 0.53529531\n",
      "Iteration 6, loss = 0.52761425\n",
      "Iteration 7, loss = 0.53425266\n",
      "Iteration 8, loss = 0.52327544\n",
      "Iteration 9, loss = 0.50877113\n",
      "Iteration 10, loss = 0.50497281\n",
      "Iteration 11, loss = 0.50074837\n",
      "Iteration 12, loss = 0.49986856\n",
      "Iteration 13, loss = 0.49451874\n",
      "Iteration 14, loss = 0.49309111\n",
      "Iteration 15, loss = 0.48717649\n",
      "Iteration 16, loss = 0.50889387\n",
      "Iteration 17, loss = 0.49003995\n",
      "Iteration 18, loss = 0.48630853\n",
      "Iteration 19, loss = 0.48386638\n",
      "Iteration 20, loss = 0.48077712\n",
      "Iteration 21, loss = 0.49360235\n",
      "Iteration 22, loss = 0.48341759\n",
      "Iteration 23, loss = 0.48575094\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.47065121\n",
      "Iteration 2, loss = 0.59653850\n",
      "Iteration 3, loss = 0.53917867\n",
      "Iteration 4, loss = 0.52372588\n",
      "Iteration 5, loss = 0.52317332\n",
      "Iteration 6, loss = 0.51119299\n",
      "Iteration 7, loss = 0.51241305\n",
      "Iteration 8, loss = 0.50700854\n",
      "Iteration 9, loss = 0.50781907\n",
      "Iteration 10, loss = 0.50327991\n",
      "Iteration 11, loss = 0.49927077\n",
      "Iteration 12, loss = 0.50024218\n",
      "Iteration 13, loss = 0.49929873\n",
      "Iteration 14, loss = 0.49473564\n",
      "Iteration 15, loss = 0.48955890\n",
      "Iteration 16, loss = 0.50048565\n",
      "Iteration 17, loss = 0.48606345\n",
      "Iteration 18, loss = 0.48894061\n",
      "Iteration 19, loss = 0.49568330\n",
      "Iteration 20, loss = 0.48533303\n",
      "Iteration 21, loss = 0.48879452\n",
      "Iteration 22, loss = 0.48443004\n",
      "Iteration 23, loss = 0.48732269\n",
      "Iteration 24, loss = 0.48500033\n",
      "Iteration 25, loss = 0.48344861\n",
      "Iteration 26, loss = 0.48056611\n",
      "Iteration 27, loss = 0.48229781\n",
      "Iteration 28, loss = 0.48005729\n",
      "Iteration 29, loss = 0.47674016\n",
      "Iteration 30, loss = 0.47683776\n",
      "Iteration 31, loss = 0.48005360\n",
      "Iteration 32, loss = 0.47505548\n",
      "Iteration 33, loss = 0.47462468\n",
      "Iteration 34, loss = 0.47553742\n",
      "Iteration 35, loss = 0.47426090\n",
      "Iteration 36, loss = 0.47665374\n",
      "Iteration 37, loss = 0.47803331\n",
      "Iteration 38, loss = 0.48136254\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.36183466\n",
      "Iteration 2, loss = 0.59433370\n",
      "Iteration 3, loss = 0.52502273\n",
      "Iteration 4, loss = 0.51160970\n",
      "Iteration 5, loss = 0.51237364\n",
      "Iteration 6, loss = 0.50530357\n",
      "Iteration 7, loss = 0.50408913\n",
      "Iteration 8, loss = 0.50012997\n",
      "Iteration 9, loss = 0.49632324\n",
      "Iteration 10, loss = 0.49841458\n",
      "Iteration 11, loss = 0.49368235\n",
      "Iteration 12, loss = 0.49633684\n",
      "Iteration 13, loss = 0.49441218\n",
      "Iteration 14, loss = 0.49018326\n",
      "Iteration 15, loss = 0.48175804\n",
      "Iteration 16, loss = 0.48990773\n",
      "Iteration 17, loss = 0.48174965\n",
      "Iteration 18, loss = 0.48020273\n",
      "Iteration 19, loss = 0.48511320\n",
      "Iteration 20, loss = 0.47660736\n",
      "Iteration 21, loss = 0.48214438\n",
      "Iteration 22, loss = 0.47440105\n",
      "Iteration 23, loss = 0.47656279\n",
      "Iteration 24, loss = 0.47746062\n",
      "Iteration 25, loss = 0.47802988\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.51546684\n",
      "Iteration 2, loss = 0.57386843\n",
      "Iteration 3, loss = 0.53114522\n",
      "Iteration 4, loss = 0.51905064\n",
      "Iteration 5, loss = 0.51494356\n",
      "Iteration 6, loss = 0.50650406\n",
      "Iteration 7, loss = 0.50889021\n",
      "Iteration 8, loss = 0.50225248\n",
      "Iteration 9, loss = 0.49675311\n",
      "Iteration 10, loss = 0.49912717\n",
      "Iteration 11, loss = 0.49664310\n",
      "Iteration 12, loss = 0.49301806\n",
      "Iteration 13, loss = 0.49562637\n",
      "Iteration 14, loss = 0.49310116\n",
      "Iteration 15, loss = 0.49143638\n",
      "Iteration 16, loss = 0.48578364\n",
      "Iteration 17, loss = 0.48676713\n",
      "Iteration 18, loss = 0.47984358\n",
      "Iteration 19, loss = 0.48123379\n",
      "Iteration 20, loss = 0.48015586\n",
      "Iteration 21, loss = 0.48773703\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.18809860\n",
      "Iteration 2, loss = 0.57068649\n",
      "Iteration 3, loss = 0.53546991\n",
      "Iteration 4, loss = 0.52795931\n",
      "Iteration 5, loss = 0.52579937\n",
      "Iteration 6, loss = 0.51301501\n",
      "Iteration 7, loss = 0.50190998\n",
      "Iteration 8, loss = 0.50102345\n",
      "Iteration 9, loss = 0.49342888\n",
      "Iteration 10, loss = 0.49231603\n",
      "Iteration 11, loss = 0.49237076\n",
      "Iteration 12, loss = 0.49213377\n",
      "Iteration 13, loss = 0.48859809\n",
      "Iteration 14, loss = 0.48560521\n",
      "Iteration 15, loss = 0.48213363\n",
      "Iteration 16, loss = 0.48068459\n",
      "Iteration 17, loss = 0.48327373\n",
      "Iteration 18, loss = 0.47651159\n",
      "Iteration 19, loss = 0.48035166\n",
      "Iteration 20, loss = 0.47620320\n",
      "Iteration 21, loss = 0.47395839\n",
      "Iteration 22, loss = 0.47389917\n",
      "Iteration 23, loss = 0.47454121\n",
      "Iteration 24, loss = 0.46976573\n",
      "Iteration 25, loss = 0.47476163\n",
      "Iteration 26, loss = 0.46857148\n",
      "Iteration 27, loss = 0.47099577\n",
      "Iteration 28, loss = 0.47064448\n",
      "Iteration 29, loss = 0.46483402\n",
      "Iteration 30, loss = 0.46908416\n",
      "Iteration 31, loss = 0.46516171\n",
      "Iteration 32, loss = 0.46630329\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.18428999\n",
      "Iteration 2, loss = 0.55540557\n",
      "Iteration 3, loss = 0.52695064\n",
      "Iteration 4, loss = 0.51926151\n",
      "Iteration 5, loss = 0.51698435\n",
      "Iteration 6, loss = 0.50834419\n",
      "Iteration 7, loss = 0.50669664\n",
      "Iteration 8, loss = 0.50374767\n",
      "Iteration 9, loss = 0.50704221\n",
      "Iteration 10, loss = 0.50367764\n",
      "Iteration 11, loss = 0.49923887\n",
      "Iteration 12, loss = 0.50095445\n",
      "Iteration 13, loss = 0.49648385\n",
      "Iteration 14, loss = 0.49500216\n",
      "Iteration 15, loss = 0.49062735\n",
      "Iteration 16, loss = 0.49245443\n",
      "Iteration 17, loss = 0.49015657\n",
      "Iteration 18, loss = 0.49201678\n",
      "Iteration 19, loss = 0.48693004\n",
      "Iteration 20, loss = 0.48553455\n",
      "Iteration 21, loss = 0.48621821\n",
      "Iteration 22, loss = 0.48939553\n",
      "Iteration 23, loss = 0.48369453\n",
      "Iteration 24, loss = 0.47810265\n",
      "Iteration 25, loss = 0.48237806\n",
      "Iteration 26, loss = 0.48190028\n",
      "Iteration 27, loss = 0.47852241\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.54145873\n",
      "Iteration 2, loss = 0.63298020\n",
      "Iteration 3, loss = 0.55944058\n",
      "Iteration 4, loss = 0.54374500\n",
      "Iteration 5, loss = 0.52527575\n",
      "Iteration 6, loss = 0.51516011\n",
      "Iteration 7, loss = 0.51621872\n",
      "Iteration 8, loss = 0.50569941\n",
      "Iteration 9, loss = 0.50110184\n",
      "Iteration 10, loss = 0.49374417\n",
      "Iteration 11, loss = 0.49200459\n",
      "Iteration 12, loss = 0.48596560\n",
      "Iteration 13, loss = 0.48952508\n",
      "Iteration 14, loss = 0.48699426\n",
      "Iteration 15, loss = 0.49620219\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.59586065\n",
      "Iteration 2, loss = 0.59996715\n",
      "Iteration 3, loss = 0.54876264\n",
      "Iteration 4, loss = 0.53066195\n",
      "Iteration 5, loss = 0.52589170\n",
      "Iteration 6, loss = 0.51861085\n",
      "Iteration 7, loss = 0.51014537\n",
      "Iteration 8, loss = 0.50767877\n",
      "Iteration 9, loss = 0.51324499\n",
      "Iteration 10, loss = 0.49283616\n",
      "Iteration 11, loss = 0.49579039\n",
      "Iteration 12, loss = 0.50175358\n",
      "Iteration 13, loss = 0.48801758\n",
      "Iteration 14, loss = 0.48562526\n",
      "Iteration 15, loss = 0.48216750\n",
      "Iteration 16, loss = 0.49103970\n",
      "Iteration 17, loss = 0.48893090\n",
      "Iteration 18, loss = 0.48113045\n",
      "Iteration 19, loss = 0.47851502\n",
      "Iteration 20, loss = 0.47767045\n",
      "Iteration 21, loss = 0.48458875\n",
      "Iteration 22, loss = 0.48020108\n",
      "Iteration 23, loss = 0.48279931\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.56058021\n",
      "Iteration 2, loss = 0.56621676\n",
      "Iteration 3, loss = 0.52995101\n",
      "Iteration 4, loss = 0.51658702\n",
      "Iteration 5, loss = 0.51183636\n",
      "Iteration 6, loss = 0.51823342\n",
      "Iteration 7, loss = 0.50995294\n",
      "Iteration 8, loss = 0.50747231\n",
      "Iteration 9, loss = 0.49980968\n",
      "Iteration 10, loss = 0.49162220\n",
      "Iteration 11, loss = 0.49281489\n",
      "Iteration 12, loss = 0.50084375\n",
      "Iteration 13, loss = 0.49056093\n",
      "Iteration 14, loss = 0.48809255\n",
      "Iteration 15, loss = 0.48655796\n",
      "Iteration 16, loss = 0.49201475\n",
      "Iteration 17, loss = 0.48171434\n",
      "Iteration 18, loss = 0.48568326\n",
      "Iteration 19, loss = 0.48047995\n",
      "Iteration 20, loss = 0.48217362\n",
      "Iteration 21, loss = 0.48323023\n",
      "Iteration 22, loss = 0.47931541\n",
      "Iteration 23, loss = 0.48396767\n",
      "Iteration 24, loss = 0.47455157\n",
      "Iteration 25, loss = 0.47527643\n",
      "Iteration 26, loss = 0.47252348\n",
      "Iteration 27, loss = 0.47004848\n",
      "Iteration 28, loss = 0.47295501\n",
      "Iteration 29, loss = 0.46639017\n",
      "Iteration 30, loss = 0.46901522\n",
      "Iteration 31, loss = 0.46750128\n",
      "Iteration 32, loss = 0.46863605\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.50418944\n",
      "Iteration 2, loss = 0.58888566\n",
      "Iteration 3, loss = 0.53976993\n",
      "Iteration 4, loss = 0.51393738\n",
      "Iteration 5, loss = 0.51173949\n",
      "Iteration 6, loss = 0.51021623\n",
      "Iteration 7, loss = 0.50578657\n",
      "Iteration 8, loss = 0.50790842\n",
      "Iteration 9, loss = 0.49806572\n",
      "Iteration 10, loss = 0.49530387\n",
      "Iteration 11, loss = 0.49758447\n",
      "Iteration 12, loss = 0.49014396\n",
      "Iteration 13, loss = 0.49432979\n",
      "Iteration 14, loss = 0.48570424\n",
      "Iteration 15, loss = 0.48866149\n",
      "Iteration 16, loss = 0.48862316\n",
      "Iteration 17, loss = 0.48408056\n",
      "Iteration 18, loss = 0.47870521\n",
      "Iteration 19, loss = 0.48409996\n",
      "Iteration 20, loss = 0.48032741\n",
      "Iteration 21, loss = 0.48821880\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.86183238\n",
      "Iteration 2, loss = 0.63150449\n",
      "Iteration 3, loss = 0.56561541\n",
      "Iteration 4, loss = 0.53896434\n",
      "Iteration 5, loss = 0.53529531\n",
      "Iteration 6, loss = 0.52761425\n",
      "Iteration 7, loss = 0.53425266\n",
      "Iteration 8, loss = 0.52327544\n",
      "Iteration 9, loss = 0.50877113\n",
      "Iteration 10, loss = 0.50497281\n",
      "Iteration 11, loss = 0.50074837\n",
      "Iteration 12, loss = 0.49986856\n",
      "Iteration 13, loss = 0.49451874\n",
      "Iteration 14, loss = 0.49309111\n",
      "Iteration 15, loss = 0.48717649\n",
      "Iteration 16, loss = 0.50889387\n",
      "Iteration 17, loss = 0.49003995\n",
      "Iteration 18, loss = 0.48630853\n",
      "Iteration 19, loss = 0.48386638\n",
      "Iteration 20, loss = 0.48077712\n",
      "Iteration 21, loss = 0.49360235\n",
      "Iteration 22, loss = 0.48341759\n",
      "Iteration 23, loss = 0.48575094\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.47065121\n",
      "Iteration 2, loss = 0.59653850\n",
      "Iteration 3, loss = 0.53917867\n",
      "Iteration 4, loss = 0.52372588\n",
      "Iteration 5, loss = 0.52317332\n",
      "Iteration 6, loss = 0.51119299\n",
      "Iteration 7, loss = 0.51241305\n",
      "Iteration 8, loss = 0.50700854\n",
      "Iteration 9, loss = 0.50781907\n",
      "Iteration 10, loss = 0.50327991\n",
      "Iteration 11, loss = 0.49927077\n",
      "Iteration 12, loss = 0.50024218\n",
      "Iteration 13, loss = 0.49929873\n",
      "Iteration 14, loss = 0.49473564\n",
      "Iteration 15, loss = 0.48955890\n",
      "Iteration 16, loss = 0.50048565\n",
      "Iteration 17, loss = 0.48606345\n",
      "Iteration 18, loss = 0.48894061\n",
      "Iteration 19, loss = 0.49568330\n",
      "Iteration 20, loss = 0.48533303\n",
      "Iteration 21, loss = 0.48879452\n",
      "Iteration 22, loss = 0.48443004\n",
      "Iteration 23, loss = 0.48732269\n",
      "Iteration 24, loss = 0.48500033\n",
      "Iteration 25, loss = 0.48344861\n",
      "Iteration 26, loss = 0.48056611\n",
      "Iteration 27, loss = 0.48229781\n",
      "Iteration 28, loss = 0.48005729\n",
      "Iteration 29, loss = 0.47674016\n",
      "Iteration 30, loss = 0.47683776\n",
      "Iteration 31, loss = 0.48005360\n",
      "Iteration 32, loss = 0.47505548\n",
      "Iteration 33, loss = 0.47462468\n",
      "Iteration 34, loss = 0.47553742\n",
      "Iteration 35, loss = 0.47426090\n",
      "Iteration 36, loss = 0.47665374\n",
      "Iteration 37, loss = 0.47803331\n",
      "Iteration 38, loss = 0.48136254\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.36183466\n",
      "Iteration 2, loss = 0.59433370\n",
      "Iteration 3, loss = 0.52502273\n",
      "Iteration 4, loss = 0.51160970\n",
      "Iteration 5, loss = 0.51237364\n",
      "Iteration 6, loss = 0.50530357\n",
      "Iteration 7, loss = 0.50408913\n",
      "Iteration 8, loss = 0.50012997\n",
      "Iteration 9, loss = 0.49632324\n",
      "Iteration 10, loss = 0.49841458\n",
      "Iteration 11, loss = 0.49368235\n",
      "Iteration 12, loss = 0.49633684\n",
      "Iteration 13, loss = 0.49441218\n",
      "Iteration 14, loss = 0.49018326\n",
      "Iteration 15, loss = 0.48175804\n",
      "Iteration 16, loss = 0.48990773\n",
      "Iteration 17, loss = 0.48174965\n",
      "Iteration 18, loss = 0.48020273\n",
      "Iteration 19, loss = 0.48511320\n",
      "Iteration 20, loss = 0.47660736\n",
      "Iteration 21, loss = 0.48214438\n",
      "Iteration 22, loss = 0.47440105\n",
      "Iteration 23, loss = 0.47656279\n",
      "Iteration 24, loss = 0.47746062\n",
      "Iteration 25, loss = 0.47802988\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.51546684\n",
      "Iteration 2, loss = 0.57386843\n",
      "Iteration 3, loss = 0.53114522\n",
      "Iteration 4, loss = 0.51905064\n",
      "Iteration 5, loss = 0.51494356\n",
      "Iteration 6, loss = 0.50650406\n",
      "Iteration 7, loss = 0.50889021\n",
      "Iteration 8, loss = 0.50225248\n",
      "Iteration 9, loss = 0.49675311\n",
      "Iteration 10, loss = 0.49912717\n",
      "Iteration 11, loss = 0.49664310\n",
      "Iteration 12, loss = 0.49301806\n",
      "Iteration 13, loss = 0.49562637\n",
      "Iteration 14, loss = 0.49310116\n",
      "Iteration 15, loss = 0.49143638\n",
      "Iteration 16, loss = 0.48578364\n",
      "Iteration 17, loss = 0.48676713\n",
      "Iteration 18, loss = 0.47984358\n",
      "Iteration 19, loss = 0.48123379\n",
      "Iteration 20, loss = 0.48015586\n",
      "Iteration 21, loss = 0.48773703\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.18809860\n",
      "Iteration 2, loss = 0.57068649\n",
      "Iteration 3, loss = 0.53546991\n",
      "Iteration 4, loss = 0.52795931\n",
      "Iteration 5, loss = 0.52579937\n",
      "Iteration 6, loss = 0.51301501\n",
      "Iteration 7, loss = 0.50190998\n",
      "Iteration 8, loss = 0.50102345\n",
      "Iteration 9, loss = 0.49342888\n",
      "Iteration 10, loss = 0.49231603\n",
      "Iteration 11, loss = 0.49237076\n",
      "Iteration 12, loss = 0.49213377\n",
      "Iteration 13, loss = 0.48859809\n",
      "Iteration 14, loss = 0.48560521\n",
      "Iteration 15, loss = 0.48213363\n",
      "Iteration 16, loss = 0.48068459\n",
      "Iteration 17, loss = 0.48327373\n",
      "Iteration 18, loss = 0.47651159\n",
      "Iteration 19, loss = 0.48035166\n",
      "Iteration 20, loss = 0.47620320\n",
      "Iteration 21, loss = 0.47395839\n",
      "Iteration 22, loss = 0.47389917\n",
      "Iteration 23, loss = 0.47454121\n",
      "Iteration 24, loss = 0.46976573\n",
      "Iteration 25, loss = 0.47476163\n",
      "Iteration 26, loss = 0.46857148\n",
      "Iteration 27, loss = 0.47099577\n",
      "Iteration 28, loss = 0.47064448\n",
      "Iteration 29, loss = 0.46483402\n",
      "Iteration 30, loss = 0.46908416\n",
      "Iteration 31, loss = 0.46516171\n",
      "Iteration 32, loss = 0.46630329\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.18428999\n",
      "Iteration 2, loss = 0.55540557\n",
      "Iteration 3, loss = 0.52695064\n",
      "Iteration 4, loss = 0.51926151\n",
      "Iteration 5, loss = 0.51698435\n",
      "Iteration 6, loss = 0.50834419\n",
      "Iteration 7, loss = 0.50669664\n",
      "Iteration 8, loss = 0.50374767\n",
      "Iteration 9, loss = 0.50704221\n",
      "Iteration 10, loss = 0.50367764\n",
      "Iteration 11, loss = 0.49923887\n",
      "Iteration 12, loss = 0.50095445\n",
      "Iteration 13, loss = 0.49648385\n",
      "Iteration 14, loss = 0.49500216\n",
      "Iteration 15, loss = 0.49062735\n",
      "Iteration 16, loss = 0.49245443\n",
      "Iteration 17, loss = 0.49015657\n",
      "Iteration 18, loss = 0.49201678\n",
      "Iteration 19, loss = 0.48693004\n",
      "Iteration 20, loss = 0.48553455\n",
      "Iteration 21, loss = 0.48621821\n",
      "Iteration 22, loss = 0.48939553\n",
      "Iteration 23, loss = 0.48369453\n",
      "Iteration 24, loss = 0.47810265\n",
      "Iteration 25, loss = 0.48237806\n",
      "Iteration 26, loss = 0.48190028\n",
      "Iteration 27, loss = 0.47852241\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4.54145873\n",
      "Iteration 2, loss = 0.63298020\n",
      "Iteration 3, loss = 0.55944058\n",
      "Iteration 4, loss = 0.54374500\n",
      "Iteration 5, loss = 0.52527575\n",
      "Iteration 6, loss = 0.51516011\n",
      "Iteration 7, loss = 0.51621872\n",
      "Iteration 8, loss = 0.50569941\n",
      "Iteration 9, loss = 0.50110184\n",
      "Iteration 10, loss = 0.49374417\n",
      "Iteration 11, loss = 0.49200459\n",
      "Iteration 12, loss = 0.48596560\n",
      "Iteration 13, loss = 0.48952508\n",
      "Iteration 14, loss = 0.48699426\n",
      "Iteration 15, loss = 0.49620219\n",
      "Training loss did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n",
      "[array([0.80240964, 0.78795181, 0.78795181, 0.8       , 0.8       ,\n",
      "       0.77590361, 0.80963855, 0.78313253, 0.80676329, 0.77239709])]\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "clf.fit(x_train, y_train)\n",
    "results = []\n",
    "cv_results = cross_val_score(clf, x_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "cv_results_f_mlp = cross_val_score(clf, x_train, y_train, cv=10, scoring=\"f1\")\n",
    "results.append(cv_results)\n",
    "results.append(cv_results_f_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(df_test)\n",
    "with open(PREDICTION_FILE, \"w+\") as f:\n",
    "    for number in predictions:\n",
    "        f.write(str(number)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
